# LLM Learning

A project dedicated to exploring, experimenting with, and understanding Large Language Models (LLMs). This repository serves as a learning hub for building, fine-tuning, evaluating, and deploying LLMs for various NLP tasks.

## 🧠 Objectives

- Understand the architecture of popular LLMs (GPT, BERT, LLaMA, etc.)
- Experiment with fine-tuning techniques
- Implement prompt engineering strategies
- Explore retrieval-augmented generation (RAG)
- Evaluate LLM outputs using industry benchmarks
- Build simple LLM-powered applications

## 🗂️ Project Structure
llm-learning/ ├── notebooks/ # Jupyter notebooks for experiments and exploration ├── models/ # Scripts related to model training and inference ├── data/ # Sample datasets and preprocessing scripts ├── utils/ # Helper functions and utilities ├── app/ # Code for demo apps using LLMs ├── requirements.txt # Required Python packages └── README.md # Project overview and instructions


## 🚀 Getting Started

### Prerequisites

- Python 3.8+
- pip
- (Optional) Conda

### Installation

```bash
git clone https://github.ibm.com/Sriharivelan-N-K/llm-learning.git
cd llm-learning
pip install -r requirements.txt
Running an Example

You can explore any notebook under notebooks/, such as:

jupyter notebook notebooks/basic_llm_intro.ipynb
📦 Features

✅ Pretrained LLM usage with HuggingFace
✅ Prompt engineering demos
✅ Retrieval-Augmented Generation (RAG) pipeline
✅ Evaluation with BLEU/ROUGE/LLM-as-a-judge
✅ Streamlit-based demo apps
📚 Resources

LangChain
LLM University by Cohere
🙌 Contributing

Pull requests are welcome! Feel free to fork the repo and submit improvements.

🧑‍💻 Maintainer

Sriharivelan N K
IBM Research

📄 License

[IBM Internal Use Only] – This project is intended for IBM employees and collaborators.

